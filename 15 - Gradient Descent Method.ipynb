{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Method of Steepest Descest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepest_descent( x_0, f, J, tol, maxiter):\n",
    "    for i in range(maxiter):\n",
    "        alpha = 1\n",
    "        conv=False\n",
    "        while f(x_0 - alpha * J(x_0))>=f(x_0):\n",
    "            alpha = alpha/2\n",
    "            if (alpha < tol):\n",
    "                break\n",
    "        x_1 = x_0 - alpha * J(x_0)\n",
    "        if np.linalg.norm(x_1-x_0)<tol:\n",
    "            conv=True\n",
    "            break\n",
    "        x_0=x_1\n",
    "    return x_0,i+1,conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x : x[0]**2+x[1]**2\n",
    "J = lambda x : np.array([2*x[0],2*x[1]])\n",
    "x_0 = np.array([15,15])\n",
    "tol = 10**-2\n",
    "maxiter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "minx,iter,conv=steepest_descent(x_0, f, J, tol, maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0.]), 2, True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minx,iter,conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 - Conjugate Gradient Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate_gradient(x_0, b, Q, tol=0.0001):\n",
    "    r_0 = (Q @ x_0 - b)\n",
    "    d_0 = -r_0\n",
    "    k = 0\n",
    "    while np.linalg.norm(r_0)>tol:\n",
    "        alpha = (r_0.T @ r_0)/(d_0.T @ Q @ d_0)\n",
    "        x_1 = x_0 + alpha * d_0\n",
    "        r_1 = r_0 + alpha * Q @ d_0\n",
    "        beta = (r_1.T @ r_1)/(r_0.T @ r_0)\n",
    "        d_1 = -r_1 + beta * d_0\n",
    "        k+=1\n",
    "        \n",
    "        r_0 = r_1\n",
    "        d_0 = d_1\n",
    "        x_0 = x_1\n",
    "    return x_0, k\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = np.array([2,3])[None].T\n",
    "b = np.array([1,1])[None].T\n",
    "Q = np.array([[1,0],[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value: \n",
      " [[1.]\n",
      " [1.]]\n",
      "iteration value:  1\n"
     ]
    }
   ],
   "source": [
    "minx, k=conjugate_gradient(x_0, b, Q, tol=0.0001)\n",
    "print(\"min value: \\n\",minx)\n",
    "print(\"iteration value: \",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
